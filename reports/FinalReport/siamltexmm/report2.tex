\documentclass[final]{siamltexmm}
\documentclass[10pt,a4paper]{article}

\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{mathtools}
\usepackage{amsmath}

\usepackage{graphicx}
\usepackage{subfig}

\newcommand{\pe}{\psi}
\def\d{\delta} 
\def\ds{\displaystyle} 
\def\e{{\epsilon}} 
\def\eb{\bar{\eta}}  
\def\enorm#1{\|#1\|_2} 
\def\Fp{F^\prime}  
\def\fishpack{{FISHPACK}} 
\def\fortran{{FORTRAN}} 
\def\gmres{{GMRES}} 
\def\gmresm{{\rm GMRES($m$)}} 
\def\Kc{{\cal K}} 
\def\norm#1{\|#1\|} 
\def\wb{{\bar w}} 
\def\zb{{\bar z}} 

\DeclareMathOperator*{\argmin}{arg\,min} % Jan Hlavacek

% some definitions of bold math italics to make typing easier.
% They are used in the corollary.

\def\bfE{\mbox{\boldmath$E$}}
\def\bfG{\mbox{\boldmath$G$}}

\title{Independent Study -- Learning Music Structure by Laplacian Formula}
\author{Peter Yun-shao Sung\thanks{\tt yss265@nyu.edu} }

\begin{document}
\maketitle

\begin{abstract}
There are many approaches to analyzing music structure by features extracted from dimension of time series. With contruction of similarity matrix, repeated pattern can be captured which is the building block for large-scale structure. This is the work based on the Laplacian Matrix, which is essential start point of spectral clustering. We introduce variables that are trainable to reduce the cost of Laplacian Matrix from true lable, and we run this method on wide variable of music recordings. Finally, we demonstrate using these trained variable for performing music segmentation.
\end{abstract}

\pagestyle{myheadings}
\thispagestyle{plain}
\section{Laplacian formula}
Normalized Laplacian matrix is the essential start point for identifying music segmentation, and the correct boundary detection is done in my baseline approach (Ref 2). For proper boundary detection, we woule like to train the initial laplacian matrix ($L$) close to true laplacian ($L^{\ast}$) from true inerval annotation from SALAMI dataset. Therefore, to train and update the model, this section is for deriving the $L$ and ${\partial L \over \partial w_{i,j}}$, which $W_{i,j}$ representing the recurrence weighting between time point $i$ and $j$.\\
Given the definition of normalized laplacian matrix:
\begin{equation}
L := I - D^{1 \over 2}W D^{1 \over 2}
\end{equation}
D is degree matrix defined as the diagnal matrix with degrees $d_1, d_2, \ldots, d_n$, which $d_i$ is accumulation of $w_{i,j}$ which defined as followed:
\begin{equation}
d_i = \displaystyle\sum_{j \neq i}^{n} w_{ij}
\end{equation}

After multiplication and the result of equation 1.1 can be rewrite as:
\begin{equation}
L := I - D^{1 \over 2}W D^{1 \over 2} =
\begin{pmatrix}
  1 & {-w_{12} \over \sqrt{d_1d_2}} & \cdots & {-w_{1n} \over \sqrt{d_1d_n}} \\
  {-w_{21} \over \sqrt{d_2d_1}} & 1 & \cdots & {-w_{2n} \over \sqrt{d_2d_n}} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  {-w_{n1} \over \sqrt{d_nd_1}} & {-w_{n2} \over \sqrt{d_nd_2}} & \cdots & 1 \\
\end{pmatrix}
=
\begin{cases}
  {-w_{i,j} \over \sqrt{d_id_j}}       & \quad \text{if } i \neq j\\
  1   & \quad \text{if } i = j\\
\end{cases}
\end{equation}

To take the derivative of $L$ w.r.t $w_{i,j}$. Results is as follow and detail derivation is in appendix 2.1:
\begin{equation}
{\partial L \over \partial w_{i,j}} =
\begin{cases}
  0       & \quad \text{, if $i = j$}\\
  {-1 \over \sqrt{d_id_j}} + {w_{i,j}(d_i+d_j) \over 2(d_id_i)^{3\over 2}} & \quad \text{, for position $(i,j), (j,i)$} \\
  {w_{l,k} \over 2\sqrt{d_k}d_l^{3\over2}}       & \quad \text{, for all position $(l,k), (k,l)$, where $k \neq i \& j$ and $l = i\|j$}\\
  0 & \quad \text{, for any other position} \\
\end{cases}
\end{equation}
The key idea of this derivation is that, when taking derivative of $w_{i,j}$ all elements on the i-th and j-th row and column will be altered because of the degree from equation 1.2 changed.
\section{Methods}
Here is the section describing methods being used for data and matrix process.

\subsection{Data}
The data I used is mainly from SALAMI dataset. Here I have 333 audio files in mp3 format, and each music has segment annotation based on functions, uppercase, and uppercase, and most of time there are two annotators. Here I only used uppercase annotation from first annotator.

\subsection{Feature Extraction}
Each imported signal has two tracks, and all following analysis is based on the first track, and feature extraction is done by librosa cqt computing the constant-Q transform of an audio signal. As we will get too little information at low frequencies and too much information at high frequencies if we just simply double the frequency for Fourier transformation(Ref4), and cqt will be better suit for extracting feature from music signal because it spaced the center frequencies of the frequency bins geometrically, and Q-factors are all equal (Ref 5).

\subsection{Recurrent Matrix}
Each cqt-proccessed signal will be normalized followed by librosa\_beat\_beat\_track and librosa\_feature\_sync. The purpose of beat\_track function is to pick peaks in onset strength that  is approximately consistent with estimated tempo. The sync function is to use those beats to synchronous aggregate cqt signals for dimension reduction, and here I use medium as aggregation method. One issue will be raised during this process: since all music segment annotation is labeled on time-domain, how to convert the label from time to frame, and further from frame to beat will need to considered. Conversion from time to frame is not hard, given the sampleing rate and hop\_length, librosa already has fusion performing task for this purpose. By check the source code of librosa\_feature\_sync, I modified the code and return not only aggregated-cqt but also a beat-frameInterval map, and input this to my function called loadInterval2Frame to perform the task of time-frame-beat conversion. Furthermore, random seed is fixed, and therefore different models can be compared.
\section{Models}
We like to build the model minimize the loss $J$ between $L$ and $L^{\ast}$, which defined as followed:
\begin{equation}
J := {1 \over 2} || L^{\ast} - L ||^2_2
=
{1 \over 2}
\sum_{\substack{i}}
\sum_{\substack{j}}
(L^{\ast}_{i,j} - L_{i,j})^2
\end{equation}
With the loss function defined, we would like to design our model with trainable variables $\theta$ that minimizing the loss fuction during the update:
\begin{equation}
\theta^{t+1} = \theta^{t} - \alpha {\partial J \over \partial \theta}
\end{equation}
\subsection{Model 1-- train on sigma}
Here we design our model with trainable varialbe $\sigma_{i,j}$, which is gaussian width to define the similarity coefficient $w_{i,j}$ between features $x_i$ and $x_j$:
\begin{equation}
w_{i,j} = exp(- ({|| x_i - x_j ||_2 \over \sigma_{i,j} })^2)
\end{equation}
As we like to minimize the loss during each of the $\sigma_{i,j}$ update (eqation 2.2), the derivitive need to expand by chain rule:
\begin{equation}
{\partial J \over \partial \sigma_{i,j}} = sum[(L - L^{\ast}) \odot {\partial L \over \partial w_{i,j}}] \cdot {\partial w_{i,j} \over \partial \sigma_{i,j}}
\end{equation}
Where $\odot$ and $sum$ are element-wise multiplication and summation respectively. The idea of this derivation is when there is slight changes on $\sigma_{i,j}$, it directly affcts $w_{i,j}$ and also all elements on i-th and j-th row and column by the degree in equation 1.2. Figure 3.1 is the test result and the relative error between numerical and analytical method are all below 1e-5.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.8\textwidth]{../fig/Ana_vs_num_relativeErr.png}
  \caption{Relative error beteen analytical and numerical method for gradient of loss w.r.t $\sigma_{i,j}$. $|f_a - f_n| \over max(|f_a|, |f_n|)$ per each try}
\end{figure}
Combining equation 3.4 and 3.2, we performed the update for each of $\sigma_{i,j}$. We are training the variables for minimizing loss on laplacian, but since laplacian is normalized version of recurrent matrix that values are hard to visualize, therefore we all showing the result on recurrence matrix. Figure 3.2 is the recurrent matrix after sigma being trained. With boundary detection (Ref 2) performed, the detected boundaries are identical. The video of recurrence matrix updates over each steps is also available in Ref 3.
\begin{figure}[H]
\centering
\begin{subfigure}
  \begin{tabular}{c}
  \includegraphics[width=75mm]{../fig/UpdateTest_num_singleII_Alpha100000_err.png}
  \end{tabular}{}
\end{subfigure}
  \begin{tabular}{c}
  \includegraphics[width=75mm]{../fig/boundary_sigma.png}
  \end{tabular}{}
\begin{subfigure}
\end{subfigure}
\caption{Top: Loss per step. Recurrence matrix of Bottom-left: true sigment annotation, and Bottom-right: trained $\sigma$ and boundary detection}
\end{figure}
\subsection{Model 2-- train on Q}
Training on Model 1 is not scalable. First is due to the traing is on $\sigma_{i,j}$, which is the similarity between time point $i$ and $j$ and cannot apply to other song. Second is due to time interval will be different for each songs. Therefore, traing on time scale is not suitable to various songs. Here we propos the other method that is trainning on cqt bin and define as follow:
\begin{equation}
\begin{aligned}
w_{i,j} &= S^T_{i,j} \cdot Q \cdot S_{i,j} = \Sigma_k (S^k_{i,j})^2 \cdot q_{k}\\
S_{i,j} &= cqt[i] - cqt[j]
\end{aligned}
\end{equation}
$Q = [q_1, q_2, ..., q_n]$ is diagnoal matrix with the shape of number of cqt bins. Therefore, we can rewrite our objective function to be:
\begin{equation}
\begin{aligned}
\argmin_Q J(L) = \argmin_Q {1\over 2}||L^{\ast} - L||^2_2
\end{aligned}
\end{equation}
And the update rule for each of $q_i$ will be:
\begin{equation}
\begin{aligned}
q_k = q_k - \alpha {\partial J \over \partial q_k}
\end{aligned}
\end{equation}
which:
\begin{equation}
\begin{aligned}
{\partial J \over \partial q_k} = \sum_{\substack{i,j}} (L_{i,j} - L_{i,j}^{\ast}) {\partial L_{i,j} \over \partial q_k}
\end{aligned}
\end{equation}
changing each $q_k$ is like changing the weight of k-th cqt frequency bin, and therefore this will affect all elements of recurrent matrix, and $w_{i,j}$, $d_i$, and $d_j$ from equation 1.3 are all the function of $q_k$:
\begin{equation}
\begin{aligned}
{\partial L_{i,j} \over \partial q_k} &= {-1 \over \sqrt{d_id_j}} {\partial w_{i,j}\over \partial q_k} + {w_{i,j} \over 2(d_id_j)^{3\over2}}({\partial d_i\over \partial q_k}d_j + d_i{\partial d_j\over \partial q_k})\\
{\partial w_{i,j} \over q_k} &= (S_{i,j}^k)^2 \\
{\partial d_i \over \partial q_k} &= \sum_{\substack{l}} (S_{l,i}^k)^2
\end{aligned}
\end{equation}
The consistancy between numerical and anlytical method are confirmed by relative differnce smaller than 1e-5, and shown in figure 3.3.
\begin{figure}[H]
  \centering
    \includegraphics[width=85mm]{../fig/Ana_vs_num_relativeErr_Q.png}
  \caption{Relative error beteen analytical and numerical method for gradient of loss w.r.t $q_k$. $|f_a - f_n| \over max(|f_a|, |f_n|)$ per each try}
\end{figure}
We first test this model on training single one song. We batch update the elements in $Q$ all at once, and as we can see from figure 3.4 there is a noticable drop in the beginning 25 epochs with step size of 5. After that there is oscillation but slightly dropping curve. Maybe model has reached to minimum, but maybe the slightly dropping curve implies the possibility at saddle point and further improvement is possible by different update method, proper step size, or different Q initiation. From Ref 6 and Ref 7 we can see the video of recurrence matrix and Q during each epoch. After Q was trained, we can see from figure 3.4 that much of the noise from initial recurrent matrix was smoothed, and the pattern in the trained recurrent matrix became similar to ture label.
\begin{figure}[H]
\centering
\begin{subfigure}
  \begin{tabular}{c}
  \includegraphics[width=85mm]{../fig/OnlyOne_Alpha5_0_epch394_err.png}
  \end{tabular}{}
\end{subfigure}
  \begin{tabular}{c}
  \includegraphics[width=100mm]{../fig/gm_Q.png}
  \end{tabular}{}
\begin{subfigure}
\end{subfigure}
\caption{Top: loss function during each epoch. Bottom: recurrence matrix of true label, matrix with initial Q, and matrix with trained Q}
\end{figure}
Although matrix after training is cleaner and similar to true label, there are still many regions are not the same as true label. Therefore, this effect reflect on the matrix of top10 eigenvector matrix in figure 3.5. As we can see maybe the top 3 eigenvector is clearly showing some features, but there are too many noise for the remaining eigenvectors. Therefore, these noise on eigenvector will make boundary detection confused for which centroid it should belong, and therefore lots of boundaries were detected. Even there existed many noise boundaries, there still many clear boundaries were detected that are the same as true label, for example the boundary at time 10, 75, 110, 160, 200, and 240, which I think is mainly due to the contribution of clearn region in figure 3.4.
\begin{figure}[H]
\centering
\begin{subfigure}
  \begin{tabular}{c}
  \includegraphics[width=85mm]{../fig/L_Q.png}
  \end{tabular}{}
\end{subfigure}
  \begin{tabular}{c}
  \includegraphics[width=85mm]{../fig/L_Boundary.png}
  \end{tabular}{}
\begin{subfigure}
\end{subfigure}
\caption{Top: matrix of top-10 eigenvectors. Bottom: boundary detection on true and train recurrence matrix (True label vs Trained model)}
\end{figure}
Since there are many noise in the matrix of top10 eigen vectors, similar to figure 3.4 but here I only used the top 3 eigen vectors and perform boundary detection. The top3 vectors can have a clearer feature, and the boundary detected is not exactly the same as true label but similar.
\begin{figure}[H]
  \centering
    \includegraphics[width=85mm]{../fig/3vector.png}
  \caption{Perform boundary detection on the first 3 eigen vectors of trained model. Left: the top 3 eigenven vector, Right: trained recurrence matrix with detected boundaries}
\end{figure}
As the result of insterested in further understand the energy landscape, I did some tests on the update for single one song. As shown in figure 3.7, initially model was trained by different learning rate $\alpha$. Small $\alpha$ lead to slow loss drop, but large $\alpha$ oscillates the curve. This pre-train was done for about 900 epochs, and then followed by post-training with same update method but different/same learning rate. Basically, if pre- and post-training is using the sample learning rate, the curve is keep decreasing and oscilation can still be oberved in $\alpha=5$, but in a very small scale, potentionally suggesting model is at a state with very slight gradient. Furthermore, if model is pre-trained with $\alpha=1$, and followed by post-train with $\alpha=5$, the loss curve will just jump out and stay the same. This implys althought loss is dropped to similar value with different learning rate, but models are now at very different energy territory, and therefore change to different learning rate will make the model jump out of its delicate state and not coming back. The test here is the same model that showing in figure 3.5, which the boundary detection is fine for some parts but not all. Therefore, this is just testing on single one song and energy trap can be observed already, then better update model or deeper layer of traing modle might required for skipping the trap and accerating the training.
\begin{figure}[H]
\centering
   \includegraphics[width=100mm]{../fig/alphaAll-01-01.png}
\caption{Loss function pre- and post-training during each epoch. Top: loss function during first 900 epochs with alpha of 1, and post training using alpha 1 and 5. Bottom: loss function during first 900 epochs with alpha of 5, and post training using alpha 5.}
\end{figure}
Then model was trained on batch of 16 music records from SALAMI dataset. Similiar to update strategy mentioned above, we update $q_i \in Q$ all at once per song, and used this new Q to update the next song. With the learning rate $\alpha = 50$, the curve of loss dropped during each epoch and then reached to a state with only small gradient, similar to what we observed on single song. As we check the video of Q during each of the update for single and batch song in Ref7 and Ref8 respectively, the growth pattern is quite different between them. For Q in single song training, generally the curve is forming a funnel-liked pattern, suggesting if we like to fit the trun laplacian matrix, certain cqt bin plays important or less important role on distanguishing feature differences between time $i$ and $j$. However, this funnel-liked pattern is not observed in training on batch songs. Maybe this implys there is tug-of-wars during the training on batch songs, and the the importants for specific cqt bin may not be the same in different songs. Figure 3.9 showes the result for each of the song after training.
\begin{figure}[H]
\centering
   \includegraphics[width=100mm]{../fig/qTestIII_Alpha50_0_epch51_err.png}
\caption{Loss function of training on 16 samples during each epoch}
\end{figure}

\begin{figure}[H]
\begin{subfigure}
  \begin{tabular*}{.01\linewidth}{@{\extracolsep{\fill}}ccc}
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID696.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID696.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID696.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1024.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1024.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1024.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1074.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1074.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1074.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1130.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1130.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1130.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1154.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1154.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1154.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1280.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1280.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1280.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1330.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1330.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1330.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1366.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1366.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1366.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1394.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1394.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1394.png}}\\
  \subfloat{\includegraphics[width = 50mm]{../fig/result/gm_ID1444.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/Y_ID1444.png}}&
  \subfloat{\includegraphics[width = 50mm]{../fig/result/B_ID1444.png}}
  \end{tabular*}
\end{subfigure}
\caption{Result of training. Left: recurrence matrix of true label, matrix before train, and matrix after train. Middle: top10 eigen vectors of true lable and trained model. Right: boundary detection of true label and trained model}
\end{figure}

\section{Discussion}
Some achievements have been done in this work:
\begin{enumerate}
\item Repoduce boundary detection on music structure
\item Wrote tools for preprocess data from SALAMI and perform time-frame-beat conversion
\item Design two models to learn Laplacian matrix by variable $\sigma$ and $Q$, and derivatives were confirmed by numerical and analytical methods.
\item Investigate the loss landscape and $Q$ curve during the training of $Q$
\item Perform boundary detection on each model
\end{enumerate}

The $Q$ model is focusing on qct bins and is scalable to batch of data. Here we shows the possibility of the model to learn from true Laplacian matrix, and perfrom boundary detection. Boundary detection is limited to only rough structure because still some regions of the laplacin cannot be the same as the true lable, and these regions introduced noise to eigenvectors limiting the boundary detection. Furthermore, when traing on batch of music, the result from the trained $Q$ matrix is not ideal, and there are still many of noise in eigenvectors and cannot perform boundaty detection well. Although boundary detection is current limited, as checking the loss curve during each epoch, the the loss state keeps decreasing but just in a very small amount, suggesting we are trapped at a flat energy state but further improvement is possible. Therefore, the future work may involve better update strategy for $Q$, introducing nonlinear property or transforming to higher dimention for translating the impact of $Q$ to recurrence weighting $W_{i,j}$.

\begin{thebibliography}{10}
\bibitem{fpf} {\sc A Tutorial on Spectral Clustering}
\bibitem{fpf} \hyperref[baseline]{''https://github.com/jfriend08/IS/blob/master/reports/midway/report.pdf''}
\bibitem{fpf} \hyperref[singleII Alpha100000II ]{''https://youtu.be/h-JTtPNF8nA''}
\bibitem{fpf} {\sc Calculation of a Constant Q Spectral Transformation}
\bibitem{fpf} {\sc Constant-Q Transform Toolbox for Music Processing}
\bibitem{fpf} \hyperref[OnlyOne Alpha5_GM ]{''https://youtu.be/bEbaQwhDSbM''}
\bibitem{fpf} \hyperref[Q_oneSong_Alpha5]{''https://youtu.be/qNF4cmplpyk''}
\bibitem{fpf} \hyperref[Q_batchMusic A50]{''https://youtu.be/CUkIuok58mg''}
\end{thebibliography}

\section{Appendix}
\subsection{Differential of Laplacian Matrix}
If we would like to take derivative of Laplacian w.r.t variable $w_{i,j}$ in the symmetric matrix $W$. Basically, except for $L_{i,j}$ the components of $L_{i,k}$, $L_{k,i}$, $L_{k,j}$, $L_{j,k}$ will need to consider.\\
For position $L_{i,j}$:
\begin{equation}
\begin{aligned}
L_{i,j} &= L_{j,i} =  {-w_{i,j} \over \sqrt{d_id_j}} \\
{\partial L_{i,j} \over \partial w_{i,j}} &= {\partial L_{j,i} \over \partial w_{i,j}} = {-1 \over \sqrt{d_id_j}} + {w_{i,j} \over 2(d_id_i)^{3\over 2}}({\partial d_i \over \partial w_{i,j}}d_j + d_i{\partial d_j \over \partial w_{i,j}}) \\
&= {-1 \over \sqrt{d_id_j}} + {w_{i,j}(d_i+d_j) \over 2(d_id_i)^{3\over 2}}
\end{aligned}
\end{equation}
For position $L_{l,k}$, $L_{k,l}$, where $k \neq i \& j$ and $l = i\|j$:
\begin{equation}
\begin{aligned}
L_{k,l} &= L_{l,k} =  {-w_{k,l} \over \sqrt{d_kd_l}} \\
{\partial L_{k,l} \over \partial w_{i,j}} &= {\partial L_{k,l} \over \partial w_{i,j}} = {w_{k,l} \over 2\sqrt{d_k}d_l^{3\over2}}
\end{aligned}
\end{equation}

\end{document}
