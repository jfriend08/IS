\documentclass[final]{siamltexmm}
\documentclass[10pt,a4paper]{article}

\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{mathtools}
\usepackage{amsmath}

% \usepackage[demo]{graphicx}
% \usepackage{subfig}

\newcommand{\pe}{\psi}
\def\d{\delta} 
\def\ds{\displaystyle} 
\def\e{{\epsilon}} 
\def\eb{\bar{\eta}}  
\def\enorm#1{\|#1\|_2} 
\def\Fp{F^\prime}  
\def\fishpack{{FISHPACK}} 
\def\fortran{{FORTRAN}} 
\def\gmres{{GMRES}} 
\def\gmresm{{\rm GMRES($m$)}} 
\def\Kc{{\cal K}} 
\def\norm#1{\|#1\|} 
\def\wb{{\bar w}} 
\def\zb{{\bar z}} 

\DeclareMathOperator*{\argmin}{arg\,min} % Jan Hlavacek

% some definitions of bold math italics to make typing easier.
% They are used in the corollary.

\def\bfE{\mbox{\boldmath$E$}}
\def\bfG{\mbox{\boldmath$G$}}

\title{Independent Study -- Learning Music Structure by Laplacian Formula}
\author{Peter Yun-shao Sung\thanks{\tt yss265@nyu.edu} }

\begin{document}
\maketitle

\begin{abstract}
There are many approaches to analyzing music structure by features extracted from dimension of time series. With contruction of similarity matrix, repeated pattern can be captured which is the building block for large-scale structure. This is the work based on the Laplacian Matrix, which is essential start point of spectral clustering. We introduce variables that are trainable to reduce the cost of Laplacian Matrix from true lable, and we run this method on wide variable of music recordings. Finally, we demonstrate using these trained variable for performing music segmentation.
\end{abstract}

\pagestyle{myheadings}
\thispagestyle{plain}

\section{Laplacian formula}
Normalized Laplacian matrix is the essential start point for identifying music segmentation, and the correct boundary detection is done in my baseline approach (Ref 2). For proper boundary detection, we woule like to train the initial laplacian matrix ($L$) close to true laplacian ($L^{\ast}$) from true inerval annotation from SALAMI dataset. Therefore, to train and update the model, this section is for deriving the $L$ and ${\partial L \over \partial w_{i,j}}$, which $W_{i,j}$ representing the recurrence weighting between time point $i$ and $j$.\\
Given the definition of normalized laplacian matrix:
\begin{equation}
L := I - D^{1 \over 2}W D^{1 \over 2}
\end{equation}
D is degree matrix defined as the diagnal matrix with degrees $d_1, d_2, \ldots, d_n$, which $d_i$ is accumulation of $w_{i,j}$ which defined as followed:
\begin{equation}
d_i = \displaystyle\sum_{j \neq i}^{n} w_{ij}
\end{equation}

After multiplication and the result of equation 1.1 can be rewrite as:
\begin{equation}
L := I - D^{1 \over 2}W D^{1 \over 2} =
\begin{pmatrix}
  1 & {-w_{12} \over \sqrt{d_1d_2}} & \cdots & {-w_{1n} \over \sqrt{d_1d_n}} \\
  {-w_{21} \over \sqrt{d_2d_1}} & 1 & \cdots & {-w_{2n} \over \sqrt{d_2d_n}} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  {-w_{n1} \over \sqrt{d_nd_1}} & {-w_{n2} \over \sqrt{d_nd_2}} & \cdots & 1 \\
\end{pmatrix}
=
\begin{cases}
  {-w_{i,j} \over \sqrt{d_id_j}}       & \quad \text{if } i \neq j\\
  1   & \quad \text{if } i = j\\
\end{cases}
\end{equation}

To take the derivative of $L$ w.r.t $w_{i,j}$. Results is as follow and detail derivation is in appendix 2.1:
\begin{equation}
{\partial L \over \partial w_{i,j}} =
\begin{cases}
  0       & \quad \text{, if $i = j$}\\
  {-1 \over \sqrt{d_id_j}} + {w_{i,j}(d_i+d_j) \over 2(d_id_i)^{3\over 2}} & \quad \text{, for position $(i,j), (j,i)$} \\
  {w_{l,k} \over 2\sqrt{d_k}d_l^{3\over2}}       & \quad \text{, for all position $(l,k), (k,l)$, where $k \neq i \& j$ and $l = i\|j$}\\
  0 & \quad \text{, for any other position} \\
\end{cases}
\end{equation}
The key idea of this derivation is that, when taking derivative of $w_{i,j}$ all elements on the i-th and j-th row and column will be altered because of the degree from equation 1.2 changed.

\section{Methods}
Here is the section describing methods being used for data and matrix process.

\subsection{Data}
The data I used is mainly from SALAMI dataset. Here I have 333 audio files in mp3 format, and each music has segment annotation based on functions, uppercase, and uppercase, and most of time there are two annotators. Here I only used uppercase annotation from first annotator.

\subsection{Feature Extraction}
Each imported signal has two tracks, and all following analysis is based on the first track, and feature extraction is done by librosa cqt computing the constant-Q transform of an audio signal. As we will get too little information at low frequencies and too much information at high frequencies if we just simply double the frequency for Fourier transformation(Ref4), and cqt will be better suit for extracting feature from music signal because it spaced the center frequencies of the frequency bins geometrically, and Q-factors are all equal (Ref 5).

\subsection{Recurrent Matrix}
Each cqt-proccessed signal will be normalized followed by librosa\_beat\_beat\_track and librosa\_feature\_sync. The purpose of beat\_track function is to pick peaks in onset strength that  is approximately consistent with estimated tempo. The sync function is to use those beats to synchronous aggregate cqt signals for dimension reduction, and here I use medium as aggregation method. One issue will be raised during this process: since all music segment annotation is labeled on time-domain, how to convert the label from time to frame, and further from frame to beat will need to considered. Conversion from time to frame is not hard, given the sampleing rate and hop\_length, librosa already has fusion performing task for this purpose. By check the source code of librosa\_feature\_sync, I modified the code and return not only aggregated-cqt but also a beat-frameInterval map, and input this to my function called loadInterval2Frame to perform the task of time-frame-beat conversion.

\section{Models}
We like to build the model minimize the loss $J$ between $L$ and $L^{\ast}$, which defined as followed:
\begin{equation}
J := {1 \over 2} || L^{\ast} - L ||^2_2
=
{1 \over 2}
\sum_{\substack{i}}
\sum_{\substack{j}}
(L^{\ast}_{i,j} - L_{i,j})^2
\end{equation}

With the loss function defined, we would like to design our model with trainable variables $\theta$ that minimizing the loss fuction during the update:
\begin{equation}
\theta^{t+1} = \theta^{t} - \alpha {\partial J \over \partial \theta}
\end{equation}

\subsection{Model 1-- train on sigma}
Here we design our model with trainable varialbe $\sigma_{i,j}$, which is gaussian width to define the similarity coefficient $w_{i,j}$ between features $x_i$ and $x_j$:
\begin{equation}
w_{i,j} = exp(- ({|| x_i - x_j ||_2 \over \sigma_{i,j} })^2)
\end{equation}
As we like to minimize the loss during each of the $\sigma_{i,j}$ update (eqation 2.2), the derivitive need to expand by chain rule:
\begin{equation}
{\partial J \over \partial \sigma_{i,j}} = sum[(L - L^{\ast}) \odot {\partial L \over \partial w_{i,j}}] \cdot {\partial w_{i,j} \over \partial \sigma_{i,j}}
\end{equation}
Where $\odot$ and $sum$ are element-wise multiplication and summation respectively. The idea of this derivation is when there is slight changes on $\sigma_{i,j}$, it directly affcts $w_{i,j}$ and also all elements on i-th and j-th row and column by the degree in equation 1.2. Figure 3.1 is the test result and the relative error between numerical and analytical method are all below 1e-5.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.8\textwidth]{../fig/Ana_vs_num_relativeErr.png}
  \caption{Deriative of loss w.r.t $\sigma_{i,j}$. Relative error $|f_a - f_n| \over max(|f_a|, |f_n|)$ per each try}
\end{figure}

Combining equation 2.4 and 2.2, we performed the update for each of $\sigma_{i,j}$. We are training the variables for minimizing loss on laplacian, but since laplacian is normalized version of recurrent matrix that values are hard to visualize, therefore we all showing the result on recurrence matrix. Figure 3.2 is the recurrent matrix after sigma being trained. With boundary detection (Ref 2) performed, the detected boundaries are identical. The video of recurrence matrix updates over each steps is also available in Ref 3.

\begin{figure}[H]
\centering
   \begin{subfigure}
   \includegraphics[width=100mm]{../fig/UpdateTest_num_singleII_Alpha100000_err.png}
\end{subfigure}

\begin{subfigure}
   \includegraphics[width=100mm]{../fig/boundary_sigma.png}
\end{subfigure}
\caption{Top: Loss per step. Recurrence matrix of Bottom-left: true sigment annotation, and Bottom-right: feature with trained sigma }
\end{figure}


\subsection{Model 2-- train on Q}
Training on Model 1 is not scalable. First is due to the traing is on $\sigma_{i,j}$, which is the similarity between time point $i$ and $j$ and cannot apply to other song. Second is due to time interval will be different for each songs. Therefore, traing on time scale is not suitable to various songs. Here we propos the other method that is trainning on cqt bin and define as follow:
\begin{equation}
\begin{aligned}
W_{i,j} &= S^T_{i,j} \cdot Q \cdot S_{i,j} = \Sigma_k (S^k_{i,j})^2 \cdot q_{k}\\
S_{i,j} &= cqt[i] - cqt[j]
\end{aligned}
\end{equation}
$Q = [q_1, q_2, ..., q_n]$ is diagnoal matrix with the shape of number of cqt bins. Therefore, we can rewrite our objective function to be:
\begin{equation}
\begin{aligned}
\argmin_Q J(L) = \argmin_Q {1\over 2}||L^{\ast} - L||^2_2
\end{aligned}
\end{equation}
And the update rule for each of $q_i$ will be:
\begin{equation}
\begin{aligned}
q_k = q_k - \alpha {\partial J \over \partial q_k}
\end{aligned}
\end{equation}
which:
\begin{equation}
\begin{aligned}
{\partial J \over \partial q_k} = \sum_{\substack{i,j}} (L_{i,j} - L_{i,j}^{\ast}) {\partial L_{i,j} \over \partial q_k}
\end{aligned}
\end{equation}
changing each $q_k$ is like changing the weight of k-th cqt frequency bin, and therefore this will affect all elements of recurrent matrix, and $w_{i,j}$, $d_i$, and $d_j$ from equation 1.3 are all the function of $q_k$:
\begin{equation}
\begin{aligned}
{\partial L_{i,j} \over \partial q_k} &= {-1 \over \sqrt{d_id_j}} {\partial w_{i,j}\over \partial q_k} + {w_{i,j} \over 2(d_id_j)^{3\over2}}({\partial d_i\over \partial q_k}d_j + d_i{\partial d_j\over \partial q_k})\\
{\partial w_{i,j} \over q_k} &= (s_{i,j}^k)^2 \\
{\partial d_i \over \partial q_k} &= \sum_{\substack{l}} (S_{l,i}^k)^2
\end{aligned}
\end{equation}
The consistancy between numerical and anlytica method are confirmed by relative differnce smaller than 1e-5, and shown in figure 3.3.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.8\textwidth]{../fig/Ana_vs_num_relativeErr_Q.png}
  \caption{Deriative of loss w.r.t $q_k$. Relative error $|f_a - f_n| \over max(|f_a|, |f_n|)$ per each try}
\end{figure}
We first test this model on training single one song. We batch update the elements in $Q$ all at once, and as we can see from figure 3.4 there is a noticable drop in the beginning 25 epochs with step size of 5. After that there is oscillation but slightly dropping curve. Maybe model has reached to minimum, but maybe the slightly dropping curve implies the possibility at saddle point and further improvement is possible by different update method or proper step size. From Ref 6 and Ref 7 we can see the changes of recurrence matrix and Q during each epoch. After Q was trained, we can see from figure 3.4 that much of the noise from initial recurrent matrix was smoothed, and the pattern in the trained recurrent matrix became similar to ture label. However, although matrix after training is cleaner and similar to true label, there are still many regions are not the same as true label. Therefore, this effect reflect on the matrix of top10 eigenvector matrix in figure 3.5. As we can see maybe the top 3 eigenvector is clear showing some features, but there are too many noise for the remaining eigenvectors.
\begin{figure}[H]
\centering
\begin{subfigure}
   \includegraphics[width=100mm]{../fig/OnlyOne_Alpha5_0_epch394_err.png}
\end{subfigure}

\begin{subfigure}
   \includegraphics[width=100mm]{../fig/gm_Q.png}
\end{subfigure}
\caption{Top: matrix of top-10 eigenvectors. Bottom: boundary detection on true and train recurrence matrix}
\end{figure}

\begin{figure}[H]
\centering
   \begin{subfigure}
   \includegraphics[width=100mm]{../fig/L_Q.png}
\end{subfigure}

\begin{subfigure}
   \includegraphics[width=100mm]{../fig/L_Boundary.png}
\end{subfigure}
\caption{Top: recurrence matrix from ture label, initial Q, and trained Q. Bottom: Laplacian matrix from true label and trained Q}
\end{figure}

\begin{thebibliography}{10}
\bibitem{fpf} {\sc A Tutorial on Spectral Clustering}
\bibitem{fpf} \hyperref[baseline]{''https://github.com/jfriend08/IS/blob/master/reports/midway/report.pdf''}
\bibitem{fpf} \hyperref[baseline]{''https://youtu.be/h-JTtPNF8nA''}
\bibitem{fpf} {\sc Calculation of a Constant Q Spectral Transformation}
\bibitem{fpf} {\sc Constant-Q Transform Toolbox for Music Processing}
\bibitem{fpf} \hyperref[baseline]{''https://youtu.be/bEbaQwhDSbM''}
\bibitem{fpf} \hyperref[baseline]{''https://youtu.be/qNF4cmplpyk''}


\end{thebibliography}

\section{Appendix}
\subsection{Differential of Laplacian Matrix}
If we would like to take derivative of Laplacian w.r.t variable $w_{i,j}$ in the symmetric matrix $W$. Basically, except for $L_{i,j}$ the components of $L_{i,k}$, $L_{k,i}$, $L_{k,j}$, $L_{j,k}$ will need to consider.\\
For position $L_{i,j}$:
\begin{equation}
\begin{aligned}
L_{i,j} &= L_{j,i} =  {-w_{i,j} \over \sqrt{d_id_j}} \\
{\partial L_{i,j} \over \partial w_{i,j}} &= {\partial L_{j,i} \over \partial w_{i,j}} = {-1 \over \sqrt{d_id_j}} + {w_{i,j} \over 2(d_id_i)^{3\over 2}}({\partial d_i \over \partial w_{i,j}}d_j + d_i{\partial d_j \over \partial w_{i,j}}) \\
&= {-1 \over \sqrt{d_id_j}} + {w_{i,j}(d_i+d_j) \over 2(d_id_i)^{3\over 2}}
\end{aligned}
\end{equation}
For position $L_{l,k}$, $L_{k,l}$, where $k \neq i \& j$ and $l = i\|j$:
\begin{equation}
\begin{aligned}
L_{k,l} &= L_{l,k} =  {-w_{k,l} \over \sqrt{d_kd_l}} \\
{\partial L_{k,l} \over \partial w_{i,j}} &= {\partial L_{k,l} \over \partial w_{i,j}} = {w_{k,l} \over 2\sqrt{d_k}d_l^{3\over2}}
\end{aligned}
\end{equation}

\end{document}
